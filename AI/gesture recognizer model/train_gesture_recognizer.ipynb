{"cells":[{"cell_type":"markdown","metadata":{"id":"cVVxZNfo0M0y"},"source":["Install the MediaPipe Model Maker package."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38626,"status":"ok","timestamp":1706265865771,"user":{"displayName":"이서현","userId":"15205162731827468443"},"user_tz":-540},"id":"6DBLRE-fqlO5","outputId":"c9f2be85-5154-4115-ef46-351360d5ab91"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n","Collecting pip\n","  Downloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 23.1.2\n","    Uninstalling pip-23.1.2:\n","      Successfully uninstalled pip-23.1.2\n","Successfully installed pip-23.3.2\n","Collecting mediapipe-model-maker\n","  Downloading mediapipe_model_maker-0.2.1.3-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (1.4.0)\n","Collecting mediapipe>=0.10.0 (from mediapipe-model-maker)\n","  Downloading mediapipe-0.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (1.23.5)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (4.8.0.76)\n","Requirement already satisfied: tensorflow>=2.10 in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (2.15.0)\n","Collecting tensorflow-addons (from mediapipe-model-maker)\n","  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (4.9.4)\n","Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (0.16.0)\n","Collecting tf-models-official>=2.13.1 (from mediapipe-model-maker)\n","  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (23.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (23.5.26)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (3.7.1)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (4.8.0.76)\n","Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (3.20.3)\n","Collecting sounddevice>=0.4.4 (from mediapipe>=0.10.0->mediapipe-model-maker)\n","  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (1.6.3)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (23.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (0.35.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (1.60.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (2.15.1)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (2.15.0)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (3.0.8)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (9.4.0)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (0.5.0)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (2.84.0)\n","Collecting immutabledict (from tf-models-official>=2.13.1->mediapipe-model-maker)\n","  Downloading immutabledict-4.1.0-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (1.5.16)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (4.1.3)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (4.9.0.80)\n","Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (1.5.3)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (5.9.5)\n","Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (9.0.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (2.0.7)\n","Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (6.0.1)\n","Collecting sacrebleu (from tf-models-official>=2.13.1->mediapipe-model-maker)\n","  Downloading sacrebleu-2.4.0-py3-none-any.whl.metadata (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (1.11.4)\n","Collecting sentencepiece (from tf-models-official>=2.13.1->mediapipe-model-maker)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting seqeval (from tf-models-official>=2.13.1->mediapipe-model-maker)\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.13.1->mediapipe-model-maker)\n","  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\n","Collecting tensorflow-text~=2.15.0 (from tf-models-official>=2.13.1->mediapipe-model-maker)\n","  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n","Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (1.1.0)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->mediapipe-model-maker)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (8.1.7)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.1.8)\n","Requirement already satisfied: etils>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->mediapipe-model-maker) (1.6.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.31.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (1.14.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.10.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (4.66.1)\n","Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.5.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.10->mediapipe-model-maker) (0.42.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->mediapipe-model-maker) (2023.6.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->mediapipe-model-maker) (6.1.1)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->mediapipe-model-maker) (3.17.0)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (0.22.0)\n","Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (2.17.3)\n","Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (0.1.1)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (2.11.1)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (4.1.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (2023.11.17)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (2.8.2)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (8.0.1)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (2.0.7)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (6.1.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official>=2.13.1->mediapipe-model-maker) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->mediapipe-model-maker) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->mediapipe-model-maker) (3.6)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (1.16.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (3.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (3.0.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (4.47.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (3.1.1)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.13.1->mediapipe-model-maker) (0.5.1)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.13.1->mediapipe-model-maker) (0.3.0)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.13.1->mediapipe-model-maker) (4.9)\n","Collecting portalocker (from sacrebleu->tf-models-official>=2.13.1->mediapipe-model-maker)\n","  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official>=2.13.1->mediapipe-model-maker) (2023.6.3)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official>=2.13.1->mediapipe-model-maker) (0.9.0)\n","Collecting colorama (from sacrebleu->tf-models-official>=2.13.1->mediapipe-model-maker)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official>=2.13.1->mediapipe-model-maker) (4.9.4)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.13.1->mediapipe-model-maker) (1.2.2)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->mediapipe-model-maker) (1.62.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (2.21)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (5.3.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (1.3.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.13.1->mediapipe-model-maker) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.13.1->mediapipe-model-maker) (3.2.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (2.1.4)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (0.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (1.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (3.2.2)\n","Downloading mediapipe_model_maker-0.2.1.3-py3-none-any.whl (127 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mediapipe-0.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading immutabledict-4.1.0-py3-none-any.whl (4.5 kB)\n","Downloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=a848b438b2746a4e5df543e1d57e80b8021df64211a95a3c8444b5901a47be0e\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","Successfully built seqeval\n","Installing collected packages: sentencepiece, typeguard, tensorflow-model-optimization, portalocker, immutabledict, colorama, tensorflow-addons, sounddevice, sacrebleu, seqeval, mediapipe, tensorflow-text, tf-models-official, mediapipe-model-maker\n","Successfully installed colorama-0.4.6 immutabledict-4.1.0 mediapipe-0.10.9 mediapipe-model-maker-0.2.1.3 portalocker-2.8.2 sacrebleu-2.4.0 sentencepiece-0.1.99 seqeval-1.2.2 sounddevice-0.4.6 tensorflow-addons-0.23.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.15.0 tf-models-official-2.15.0 typeguard-2.13.3\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install --upgrade pip\n","!pip install mediapipe-model-maker"]},{"cell_type":"markdown","metadata":{"id":"v3CvTNmB1WiY"},"source":["Import the required libraries."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6255,"status":"ok","timestamp":1706265872020,"user":{"displayName":"이서현","userId":"15205162731827468443"},"user_tz":-540},"id":"c74UL9oI0VKU","outputId":"fa7ab058-7e8e-491e-f22b-ac11e96166a0"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["from google.colab import files\n","import os\n","import tensorflow as tf\n","assert tf.__version__.startswith('2')\n","\n","from mediapipe_model_maker import gesture_recognizer\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28577,"status":"ok","timestamp":1706265900593,"user":{"displayName":"이서현","userId":"15205162731827468443"},"user_tz":-540},"id":"aKuOOGPJjTGE","outputId":"9557eff0-a078-41b0-c357-f6c3ee162480"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6dwmyg5MnR_y"},"outputs":[],"source":["dataset_path = \"/content/drive/MyDrive/Colab Notebooks/GDSC/솔챌/rps_data_sample_360\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1793,"status":"ok","timestamp":1706265902378,"user":{"displayName":"이서현","userId":"15205162731827468443"},"user_tz":-540},"id":"QgadM4VDj3Y2","outputId":"500a4faa-90d0-41c9-b2fd-4846aed4a896"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/GDSC/솔챌/rps_data_sample_360\n","['a', 'eo', 'e', 'digeut', 'ae', 'bieup', 'chieut', 'add', 'clear_all', 'clear_one', 'hieut', 'eu', 'kieuk', 'mieum', 'ieung', 'giyeok', 'jieut', 'i', 'o', 'nieun', 'space', 'pieup', 'ya', 'siot', 'oe', 'tieut', 'u', 'ui', 'rieul', 'wi', 'yae', 'yeo', 'yo', 'ye', 'yu', 'None']\n"]}],"source":["print(dataset_path)\n","labels = []\n","for i in os.listdir(dataset_path):\n","  if os.path.isdir(os.path.join(dataset_path, i)):\n","    labels.append(i)\n","print(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":171553,"status":"ok","timestamp":1706266073928,"user":{"displayName":"이서현","userId":"15205162731827468443"},"user_tz":-540},"id":"sx8PsrwYjvgO","outputId":"5faa2bf0-1aa7-4dc5-fdd6-73efadb3e834"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-7-cb51c575bd8e>:6: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n","  fig, axs = plt.subplots(1, NUM_EXAMPLES, figsize=(10,2))\n"]}],"source":["NUM_EXAMPLES = 5\n","\n","for label in labels:\n","    label_dir = os.path.join(dataset_path, label)\n","    example_filenames = os.listdir(label_dir)[:NUM_EXAMPLES]\n","    fig, axs = plt.subplots(1, NUM_EXAMPLES, figsize=(10,2))\n","    for i in range(min(NUM_EXAMPLES, len(example_filenames))):\n","        axs[i].imshow(plt.imread(os.path.join(label_dir, example_filenames[i])))\n","        axs[i].get_xaxis().set_visible(False)\n","        axs[i].get_yaxis().set_visible(False)\n","    fig.suptitle(f'Showing {NUM_EXAMPLES} examples for {label}')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":686742,"status":"ok","timestamp":1706266760663,"user":{"displayName":"이서현","userId":"15205162731827468443"},"user_tz":-540},"id":"aTTNZsolKXiT","outputId":"425e136c-5f67-406e-d37e-30d77469d748"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://storage.googleapis.com/mediapipe-assets/palm_detection_full.tflite to /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n","Downloading https://storage.googleapis.com/mediapipe-assets/hand_landmark_full.tflite to /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n","Downloading https://storage.googleapis.com/mediapipe-assets/gesture_embedder.tar.gz to /tmp/model_maker/gesture_recognizer/gesture_embedder\n"]}],"source":["data = gesture_recognizer.Dataset.from_folder(\n","    dirname=dataset_path,\n","    hparams=gesture_recognizer.HandDataPreprocessingParams()\n",")\n","train_data, rest_data = data.split(0.8)\n","validation_data, test_data = rest_data.split(0.5)"]},{"cell_type":"markdown","metadata":{"id":"ndTh_ZyEIeKV"},"source":["**Train the model**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":348603,"status":"ok","timestamp":1706267109257,"user":{"displayName":"이서현","userId":"15205162731827468443"},"user_tz":-540},"id":"yk0UiRB6NZrb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3e7d9e2b-25fb-41e2-d6c5-ccff936b4a4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," hand_embedding (InputLayer  [(None, 128)]             0         \n"," )                                                               \n","                                                                 \n"," batch_normalization (Batch  (None, 128)               512       \n"," Normalization)                                                  \n","                                                                 \n"," re_lu (ReLU)                (None, 128)               0         \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," custom_gesture_recognizer_  (None, 36)                4644      \n"," out (Dense)                                                     \n","                                                                 \n","=================================================================\n","Total params: 5156 (20.14 KB)\n","Trainable params: 4900 (19.14 KB)\n","Non-trainable params: 256 (1.00 KB)\n","_________________________________________________________________\n","None\n","Epoch 1/10\n","2032/2032 [==============================] - 35s 15ms/step - loss: 1.8885 - categorical_accuracy: 0.4284 - val_loss: 0.7613 - val_categorical_accuracy: 0.7382 - lr: 0.0010\n","Epoch 2/10\n","2032/2032 [==============================] - 29s 14ms/step - loss: 1.1914 - categorical_accuracy: 0.6093 - val_loss: 0.5729 - val_categorical_accuracy: 0.7736 - lr: 9.9000e-04\n","Epoch 3/10\n","2032/2032 [==============================] - 28s 14ms/step - loss: 1.0404 - categorical_accuracy: 0.6523 - val_loss: 0.5043 - val_categorical_accuracy: 0.7874 - lr: 9.8010e-04\n","Epoch 4/10\n","2032/2032 [==============================] - 39s 19ms/step - loss: 0.9633 - categorical_accuracy: 0.6750 - val_loss: 0.4607 - val_categorical_accuracy: 0.7913 - lr: 9.7030e-04\n","Epoch 5/10\n","2032/2032 [==============================] - 37s 18ms/step - loss: 0.9145 - categorical_accuracy: 0.6900 - val_loss: 0.4292 - val_categorical_accuracy: 0.7953 - lr: 9.6060e-04\n","Epoch 6/10\n","2032/2032 [==============================] - 28s 14ms/step - loss: 0.8849 - categorical_accuracy: 0.6996 - val_loss: 0.4103 - val_categorical_accuracy: 0.8228 - lr: 9.5099e-04\n","Epoch 7/10\n","2032/2032 [==============================] - 28s 14ms/step - loss: 0.8548 - categorical_accuracy: 0.7077 - val_loss: 0.4082 - val_categorical_accuracy: 0.8150 - lr: 9.4148e-04\n","Epoch 8/10\n","2032/2032 [==============================] - 38s 19ms/step - loss: 0.8292 - categorical_accuracy: 0.7207 - val_loss: 0.3861 - val_categorical_accuracy: 0.8209 - lr: 9.3207e-04\n","Epoch 9/10\n","2032/2032 [==============================] - 39s 19ms/step - loss: 0.8127 - categorical_accuracy: 0.7217 - val_loss: 0.3842 - val_categorical_accuracy: 0.8346 - lr: 9.2274e-04\n","Epoch 10/10\n","2032/2032 [==============================] - 38s 19ms/step - loss: 0.7983 - categorical_accuracy: 0.7224 - val_loss: 0.3850 - val_categorical_accuracy: 0.8228 - lr: 9.1352e-04\n"]}],"source":["hparams = gesture_recognizer.HParams(export_dir=\"exported_model\")\n","options = gesture_recognizer.GestureRecognizerOptions(hparams=hparams)\n","model = gesture_recognizer.GestureRecognizer.create(\n","    train_data=train_data,\n","    validation_data=validation_data,\n","    options=options\n",")"]},{"cell_type":"markdown","metadata":{"id":"nED7mdIO9YS6"},"source":["**Evaluate the model performance**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14563,"status":"ok","timestamp":1706267123813,"user":{"displayName":"이서현","userId":"15205162731827468443"},"user_tz":-540},"id":"OdOqllqx9YKy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"23ed72fd-f8d9-4540-8e03-3ec0b8cc652d"},"outputs":[{"output_type":"stream","name":"stdout","text":["509/509 [==============================] - 15s 7ms/step - loss: 0.3953 - categorical_accuracy: 0.8271\n","Test loss:0.3953494429588318, Test accuracy:0.8271119594573975\n"]}],"source":["loss, acc = model.evaluate(test_data, batch_size=1)\n","print(f\"Test loss:{loss}, Test accuracy:{acc}\")"]},{"cell_type":"markdown","metadata":{"id":"vJLramjy9gvy"},"source":["**Export to Tensorflow Lite Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2432,"status":"ok","timestamp":1706267126229,"user":{"displayName":"이서현","userId":"15205162731827468443"},"user_tz":-540},"id":"fmNaFXytijVg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"975e7ee8-fa0e-4e40-f050-6bb0882cb274"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://storage.googleapis.com/mediapipe-assets/gesture_embedder.tflite to /tmp/model_maker/gesture_recognizer/gesture_embedder.tflite\n","Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n","Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n","Downloading https://storage.googleapis.com/mediapipe-assets/canned_gesture_classifier.tflite to /tmp/model_maker/gesture_recognizer/canned_gesture_classifier.tflite\n","best_model_weights.data-00000-of-00001\tcheckpoint    gesture_recognizer.task  metadata.json\n","best_model_weights.index\t\tepoch_models  logs\n"]}],"source":["model.export_model()\n","!ls exported_model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1706267126230,"user":{"displayName":"이서현","userId":"15205162731827468443"},"user_tz":-540},"id":"7yfN_47qjjOC","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"cad979ce-e1ef-4667-85df-b6ce12d98634"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_325684bb-9e6a-4c1c-b927-2e85aebffff0\", \"gesture_recognizer.task\", 8477515)"]},"metadata":{}}],"source":["files.download('exported_model/gesture_recognizer.task')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":355072,"status":"ok","timestamp":1706267481289,"user":{"displayName":"이서현","userId":"15205162731827468443"},"user_tz":-540},"id":"CxMOI8o6iNLu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e6576d12-5983-4dda-f149-8733e8c428f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," hand_embedding (InputLayer  [(None, 128)]             0         \n"," )                                                               \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 128)               512       \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_1 (ReLU)              (None, 128)               0         \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," custom_gesture_recognizer_  (None, 36)                4644      \n"," out (Dense)                                                     \n","                                                                 \n","=================================================================\n","Total params: 5156 (20.14 KB)\n","Trainable params: 4900 (19.14 KB)\n","Non-trainable params: 256 (1.00 KB)\n","_________________________________________________________________\n","None\n","Epoch 1/10\n","2032/2032 [==============================] - 38s 18ms/step - loss: 1.7017 - categorical_accuracy: 0.4838 - val_loss: 0.5575 - val_categorical_accuracy: 0.7618 - lr: 0.0030\n","Epoch 2/10\n","2032/2032 [==============================] - 29s 14ms/step - loss: 1.2535 - categorical_accuracy: 0.5969 - val_loss: 0.4790 - val_categorical_accuracy: 0.7697 - lr: 0.0030\n","Epoch 3/10\n","2032/2032 [==============================] - 28s 14ms/step - loss: 1.1887 - categorical_accuracy: 0.6014 - val_loss: 0.4259 - val_categorical_accuracy: 0.8169 - lr: 0.0029\n","Epoch 4/10\n","2032/2032 [==============================] - 29s 14ms/step - loss: 1.1492 - categorical_accuracy: 0.6265 - val_loss: 0.3924 - val_categorical_accuracy: 0.8386 - lr: 0.0029\n","Epoch 5/10\n","2032/2032 [==============================] - 39s 19ms/step - loss: 1.1256 - categorical_accuracy: 0.6223 - val_loss: 0.4033 - val_categorical_accuracy: 0.8209 - lr: 0.0029\n","Epoch 6/10\n","2032/2032 [==============================] - 40s 20ms/step - loss: 1.0817 - categorical_accuracy: 0.6410 - val_loss: 0.3900 - val_categorical_accuracy: 0.8406 - lr: 0.0029\n","Epoch 7/10\n","2032/2032 [==============================] - 30s 15ms/step - loss: 1.0974 - categorical_accuracy: 0.6287 - val_loss: 0.3981 - val_categorical_accuracy: 0.8346 - lr: 0.0028\n","Epoch 8/10\n","2032/2032 [==============================] - 37s 18ms/step - loss: 1.0686 - categorical_accuracy: 0.6373 - val_loss: 0.4049 - val_categorical_accuracy: 0.8425 - lr: 0.0028\n","Epoch 9/10\n","2032/2032 [==============================] - 30s 15ms/step - loss: 1.0805 - categorical_accuracy: 0.6439 - val_loss: 0.4267 - val_categorical_accuracy: 0.8189 - lr: 0.0028\n","Epoch 10/10\n","2032/2032 [==============================] - 40s 19ms/step - loss: 1.0519 - categorical_accuracy: 0.6459 - val_loss: 0.4031 - val_categorical_accuracy: 0.8445 - lr: 0.0027\n"]}],"source":["hparams = gesture_recognizer.HParams(learning_rate=0.003, export_dir=\"exported_model_2\")\n","model_options = gesture_recognizer.ModelOptions(dropout_rate=0.2)\n","options = gesture_recognizer.GestureRecognizerOptions(model_options=model_options, hparams=hparams)\n","model_2 = gesture_recognizer.GestureRecognizer.create(\n","    train_data=train_data,\n","    validation_data=validation_data,\n","    options=options\n",")"]},{"cell_type":"markdown","metadata":{"id":"3cekuTJiBbv9"},"source":["Evaluate the newly trained model."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20810,"status":"ok","timestamp":1706267502090,"user":{"displayName":"이서현","userId":"15205162731827468443"},"user_tz":-540},"id":"RRH96bm-BbAo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8d0006c7-5845-40d2-b067-4308565e144b"},"outputs":[{"output_type":"stream","name":"stdout","text":["16/16 [==============================] - 14s 78ms/step - loss: 0.4169 - categorical_accuracy: 0.8448\n","Test loss:0.41689884662628174, Test accuracy:0.8447937369346619\n"]}],"source":["loss, accuracy = model_2.evaluate(test_data)\n","print(f\"Test loss:{loss}, Test accuracy:{accuracy}\")"]}],"metadata":{"colab":{"last_runtime":{"build_target":"","kind":"local"},"provenance":[{"file_id":"https://github.com/googlesamples/mediapipe/blob/main/examples/customization/gesture_recognizer.ipynb","timestamp":1705698261999}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}